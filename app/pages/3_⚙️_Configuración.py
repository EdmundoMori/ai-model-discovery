"""
P√°gina de Configuraci√≥n - Ajustes del sistema

Permite configurar par√°metros del motor de b√∫squeda y el LLM

Autor: Edmundo Mori
Fecha: 2026-02-04
"""

import streamlit as st
import sys
from pathlib import Path

# Configurar path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


st.set_page_config(page_title="Configuraci√≥n - AI Model Discovery", page_icon="‚öôÔ∏è", layout="wide")


def main():
    st.title("‚öôÔ∏è Configuraci√≥n del Sistema")
    st.markdown("Ajusta los par√°metros del motor de b√∫squeda y el LLM")
    
    # Configuraci√≥n del LLM
    st.markdown("### ü§ñ Configuraci√≥n del LLM")
    
    col1, col2 = st.columns(2)
    
    with col1:
        llm_provider = st.selectbox(
            "Proveedor LLM",
            options=["ollama", "anthropic"],
            index=0,
            help="Proveedor del modelo de lenguaje"
        )
        
        if llm_provider == "ollama":
            model = st.selectbox(
                "Modelo",
                options=[
                    "deepseek-r1:7b",
                    "deepseek-r1:1.5b",
                    "llama2:7b",
                    "mistral:7b"
                ],
                index=0,
                help="Modelo Ollama local"
            )
        else:
            model = st.selectbox(
                "Modelo",
                options=[
                    "claude-3-5-sonnet-20241022",
                    "claude-3-opus-20240229",
                    "claude-3-haiku-20240307"
                ],
                index=0,
                help="Modelo Anthropic (requiere API key)"
            )
        
        temperature = st.slider(
            "Temperatura",
            min_value=0.0,
            max_value=1.0,
            value=0.1,
            step=0.1,
            help="Mayor temperatura = respuestas m√°s creativas"
        )
    
    with col2:
        use_rag = st.checkbox(
            "Usar RAG (Retrieval Augmented Generation)",
            value=True,
            help="Usa ejemplos SPARQL para mejorar conversi√≥n"
        )
        
        if use_rag:
            top_k_examples = st.slider(
                "Top-K ejemplos RAG",
                min_value=1,
                max_value=10,
                value=3,
                help="N√∫mero de ejemplos similares a usar"
            )
        else:
            top_k_examples = 0
        
        validate_sparql = st.checkbox(
            "Validar SPARQL antes de ejecutar",
            value=True,
            help="Valida sintaxis y ejecutabilidad"
        )
    
    st.markdown("---")
    
    # Configuraci√≥n de b√∫squeda
    st.markdown("### üîç Configuraci√≥n de B√∫squeda")
    
    col1, col2 = st.columns(2)
    
    with col1:
        max_results = st.number_input(
            "M√°ximo de resultados",
            min_value=5,
            max_value=100,
            value=10,
            step=5,
            help="N√∫mero m√°ximo de resultados a retornar"
        )
        
        min_score = st.number_input(
            "Score m√≠nimo",
            min_value=0.0,
            max_value=10.0,
            value=0.0,
            step=0.5,
            help="Score m√≠nimo para incluir resultado"
        )
    
    with col2:
        timeout = st.number_input(
            "Timeout (segundos)",
            min_value=5,
            max_value=300,
            value=30,
            step=5,
            help="Tiempo m√°ximo de ejecuci√≥n"
        )
        
        cache_results = st.checkbox(
            "Cachear resultados",
            value=True,
            help="Guarda resultados para consultas repetidas"
        )
    
    st.markdown("---")
    
    # Estado del sistema
    st.markdown("### üìä Estado del Sistema")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### üéØ Text-to-SPARQL")
        st.success("‚úÖ Operacional")
        st.metric("Success Rate", "80%")
        st.metric("Executability", "100%")
    
    with col2:
        st.markdown("#### üñ•Ô∏è GPU")
        st.success("‚úÖ Activa")
        st.metric("Modelo", "NVIDIA RTX 4050")
        st.metric("Uso VRAM", "4815/6141 MB")
    
    with col3:
        st.markdown("#### üìä Grafo RDF")
        st.success("‚úÖ Cargado")
        st.metric("Modelos", "70")
        st.metric("Triples", "630")
    
    st.markdown("---")
    
    # Informaci√≥n del proyecto
    st.markdown("### üìñ Informaci√≥n del Proyecto")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üìö Componentes")
        st.markdown("""
        - ‚úÖ Multi-repository collectors (7 fuentes)
        - ‚úÖ Ontolog√≠a DAIMO
        - ‚úÖ Text-to-SPARQL con LLM
        - ‚úÖ RAG con ChromaDB (14 ejemplos)
        - ‚úÖ SearchEngine sem√°ntico
        - ‚úÖ Validador SPARQL
        - ‚úÖ Interfaz Web (Streamlit)
        """)
    
    with col2:
        st.markdown("#### üéì Tesis")
        st.markdown("""
        **T√≠tulo**: Sistema de Descubrimiento y B√∫squeda de Modelos de IA
        
        **Autor**: Edmundo Mori
        
        **A√±o**: 2026
        
        **Objetivo**: Crear un sistema de b√∫squeda sem√°ntica que integre
        m√∫ltiples repositorios de modelos de IA usando Text-to-SPARQL
        y grafos de conocimiento.
        """)
    
    st.markdown("---")
    
    # Botones de acci√≥n
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üíæ Guardar Configuraci√≥n", type="primary", use_container_width=True):
            st.success("‚úÖ Configuraci√≥n guardada")
    
    with col2:
        if st.button("üîÑ Restablecer por defecto", use_container_width=True):
            st.info("‚ÑπÔ∏è Configuraci√≥n restablecida")
    
    with col3:
        if st.button("üß™ Probar configuraci√≥n", use_container_width=True):
            with st.spinner("Probando..."):
                import time
                time.sleep(1)
                st.success("‚úÖ Configuraci√≥n v√°lida")


if __name__ == "__main__":
    main()

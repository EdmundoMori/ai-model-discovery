# ğŸ¯ GuÃ­a de Uso: BÃºsqueda Multi-MÃ©todo

Esta guÃ­a te ayudarÃ¡ a elegir el mÃ©todo correcto segÃºn tu necesidad.

---

## ğŸ“Š Â¿QuÃ© mÃ©todo usar?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TIPO DE QUERY              â”‚  MÃ‰TODO RECOMENDADO           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Palabras clave simples     â”‚  âš¡ RÃ¡pida                    â”‚
â”‚  Listados bÃ¡sicos           â”‚  âš¡ RÃ¡pida                    â”‚
â”‚  BÃºsqueda por nombre        â”‚  âš¡ RÃ¡pida                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Con filtros                â”‚  ğŸ¯ Inteligente               â”‚
â”‚  Con ordenamiento (top N)   â”‚  ğŸ¯ Inteligente               â”‚
â”‚  BÃºsqueda semÃ¡ntica         â”‚  ğŸ¯ Inteligente               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Agregaciones (count, avg)  â”‚  ğŸ§  Experta                   â”‚
â”‚  Queries complejas          â”‚  ğŸ§  Experta                   â”‚
â”‚  AnÃ¡lisis estadÃ­stico       â”‚  ğŸ§  Experta                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ BÃºsqueda RÃ¡pida - Ejemplos

### âœ… FUNCIONA BIEN:
```
âœ“ "PyTorch models"
âœ“ "computer vision"
âœ“ "NLP transformers"
âœ“ "HuggingFace BERT"
âœ“ "TensorFlow image classification"
```

### âŒ NO FUNCIONA:
```
âœ— "count models by framework"          â†’ Use ğŸ§  Experta
âœ— "top 10 models by rating"            â†’ Use ğŸ¯ Inteligente
âœ— "average rating of CV models"        â†’ Use ğŸ§  Experta
âœ— "models with more than 1000 downloads" â†’ Use ğŸ¯ Inteligente
```

### ğŸ’¡ CUÃNDO USAR:
- Necesitas resultados inmediatos (~1ms)
- Sabes las palabras clave exactas
- Quieres explorar rÃ¡pidamente el catÃ¡logo

---

## ğŸ¯ BÃºsqueda Inteligente - Ejemplos

### âœ… FUNCIONA BIEN:

#### Queries Simples (usa Hybrid):
```
âœ“ "PyTorch models for NLP"
âœ“ "high quality computer vision models"
âœ“ "BERT models from HuggingFace"
âœ“ "image classification with TensorFlow"
```

#### Queries Complejas (usa LLM):
```
âœ“ "top 10 PyTorch models by rating"
âœ“ "most popular NLP models"
âœ“ "best rated computer vision models"
âœ“ "models with more than 1000 downloads"
```

### ğŸ’¡ CUÃNDO USAR:
- No sabes si tu query es simple o compleja
- Quieres el mejor balance velocidad/precisiÃ³n
- ConfÃ­as en el sistema para elegir el sub-mÃ©todo

### ğŸ” SUB-MÃ‰TODOS:
El router decide automÃ¡ticamente:
- **Hybrid** (BM25+Dense): Para queries simples â†’ ~100ms
- **LLM+RAG**: Para queries complejas â†’ ~1000ms

---

## ğŸ§  BÃºsqueda Experta - Ejemplos

### âœ… FUNCIONA BIEN:

#### Agregaciones:
```
âœ“ "count models by framework"
âœ“ "count models by task"
âœ“ "average rating of computer vision models"
âœ“ "sum of downloads by library"
âœ“ "how many models are from HuggingFace"
```

#### Queries Complejas:
```
âœ“ "models with rating > 4.5 and downloads > 1000"
âœ“ "PyTorch models ordered by popularity"
âœ“ "top 10 NLP models with highest rating"
âœ“ "compare frameworks by number of models"
```

### ğŸ’¡ CUÃNDO USAR:
- Necesitas agregaciones (COUNT, AVG, SUM)
- Query tiene mÃºltiples condiciones
- Requieres anÃ¡lisis estadÃ­stico
- No te importa esperar 3-6 segundos

### ğŸ“Š SALIDA ESPECIAL:
Para agregaciones, muestra tabla en vez de tarjetas:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Framework  â”‚ Cantidad â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PyTorch    â”‚ 450      â”‚
â”‚ TensorFlow â”‚ 380      â”‚
â”‚ JAX        â”‚ 120      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Modo ComparaciÃ³n

Activa el checkbox **"Modo comparaciÃ³n"** para:
- Ejecutar los 3 mÃ©todos simultÃ¡neamente
- Ver quÃ© mÃ©todo funciona mejor para tu query
- Comparar tiempos de ejecuciÃ³n
- Identificar el mÃ©todo Ã³ptimo

### Ejemplo de Salida:

```
Query: "top 10 PyTorch models"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©todo          â”‚ Tiempo    â”‚ Resultadosâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âš¡ RÃ¡pida       â”‚ âŒ No aplica           â”‚
â”‚ ğŸ¯ Inteligente  â”‚ 850ms     â”‚ 10 âœ…     â”‚
â”‚ ğŸ§  Experta      â”‚ 4200ms    â”‚ 10 âœ…     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ† Mejor mÃ©todo: INTELIGENTE (mÃ¡s rÃ¡pido con mismo resultado)
```

---

## ğŸ“‹ Ejemplos por CategorÃ­a

### CategorÃ­a 1: Listados Simples

| Query | MÃ©todo Recomendado | Por quÃ© |
|-------|-------------------|---------|
| "list all AI models" | âš¡ RÃ¡pida | Listado completo sin filtros |
| "PyTorch models for NLP" | ğŸ¯ Inteligente | Filtro semÃ¡ntico |
| "models from HuggingFace" | âš¡ RÃ¡pida | Palabra clave directa |

### CategorÃ­a 2: Agregaciones

| Query | MÃ©todo Recomendado | Por quÃ© |
|-------|-------------------|---------|
| "count models by task" | ğŸ§  Experta | Requiere GROUP BY |
| "average rating of CV models" | ğŸ§  Experta | Requiere AVG() |
| "total downloads by framework" | ğŸ§  Experta | Requiere SUM() |

### CategorÃ­a 3: Filtros Complejos

| Query | MÃ©todo Recomendado | Por quÃ© |
|-------|-------------------|---------|
| "top 10 PyTorch models by rating" | ğŸ¯ Inteligente | ORDER BY + LIMIT |
| "high rated CV models with >1000 downloads" | ğŸ§  Experta | MÃºltiples filtros |
| "models from HF ordered by popularity" | ğŸ¯ Inteligente | ORDER BY simple |

---

## ğŸ¨ Tipos de PresentaciÃ³n

### Tipo 1: Listado de Modelos (Tarjetas)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. bert-base-uncased                    â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ ğŸ“¦ Repositorio: HuggingFace             â”‚
â”‚ ğŸ¯ Tarea: Natural Language Processing   â”‚
â”‚ â­ Score: 0.95                          â”‚
â”‚                                         â”‚
â”‚ [ğŸ“‹ Ver metadata completa]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Usa este formato para:**
- Listados simples
- Queries de ordenamiento
- Resultados de bÃºsqueda por palabras clave

### Tipo 2: Tabla de AgregaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tarea       â”‚ Cantidad â”‚ Promedio â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ NLP         â”‚ 450      â”‚ 4.2      â”‚
â”‚ CV          â”‚ 380      â”‚ 4.5      â”‚
â”‚ Audio       â”‚ 120      â”‚ 3.9      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL       â”‚ 950      â”‚ 4.2      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[ğŸ“¥ Descargar CSV]
```

**Usa este formato para:**
- COUNT, SUM, AVG, MAX, MIN
- GROUP BY queries
- AnÃ¡lisis estadÃ­stico

---

## ğŸ’¡ Tips y Trucos

### Tip 1: Empieza Simple
```
âŒ MAL:  "average rating of PyTorch models for NLP with >1K downloads"
âœ… BIEN: Primero: "PyTorch models for NLP"
        Luego: Afina con filtros
```

### Tip 2: Usa Modo ComparaciÃ³n para Aprender
```
ğŸ”„ Ejecuta la misma query en los 3 mÃ©todos
ğŸ“Š Observa cuÃ¡l funciona mejor
ğŸ“ Aprende quÃ© mÃ©todo usar para queries similares
```

### Tip 3: Reformula si Falla
```
Si un mÃ©todo no aplica, la app te darÃ¡ sugerencias:

âŒ "cuÃ¡ntos modelos hay"
ğŸ’¡ Sugerencia: "count models by task"
```

### Tip 4: Usa el Historial
```
ğŸ“œ El sidebar guarda tus Ãºltimas 5 bÃºsquedas
â±ï¸ Ve los tiempos de cada una
ğŸ”„ Repite queries anteriores con un clic
```

---

## ğŸš€ Casos de Uso Reales

### Caso 1: Explorador de CatÃ¡logo (Data Scientist)
**Necesidad**: Ver quÃ© modelos hay disponibles

**Workflow**:
1. âš¡ RÃ¡pida: "PyTorch models" â†’ Ver listado general
2. ğŸ¯ Inteligente: "PyTorch NLP models" â†’ Filtrar por dominio
3. ğŸ§  Experta: "count PyTorch NLP models by task" â†’ AnÃ¡lisis

### Caso 2: Investigador ML
**Necesidad**: Encontrar el mejor modelo para una tarea

**Workflow**:
1. ğŸ¯ Inteligente: "top 10 computer vision models"
2. ğŸ¯ Inteligente: "high rated CV models with >1000 downloads"
3. âš¡ RÃ¡pida: "ResNet variants" â†’ Ver opciones especÃ­ficas

### Caso 3: Analista de Datos
**Necesidad**: EstadÃ­sticas del catÃ¡logo

**Workflow**:
1. ğŸ§  Experta: "count models by framework"
2. ğŸ§  Experta: "average rating by task"
3. ğŸ§  Experta: "sum downloads by source"

---

## âš™ï¸ ConfiguraciÃ³n Recomendada

### Para Uso Diario:
```
MÃ©todo: ğŸ¯ Inteligente (router automÃ¡tico)
Max resultados: 10
Mostrar SPARQL: âœ“ (aprender de las conversiones)
Metadata completa: âœ— (solo si necesitas detalles)
Modo comparaciÃ³n: âœ—
```

### Para Aprender:
```
MÃ©todo: Probar todos
Max resultados: 5 (mÃ¡s rÃ¡pido)
Mostrar SPARQL: âœ“
Metadata completa: âœ“
Modo comparaciÃ³n: âœ“ (ver diferencias)
```

### Para AnÃ¡lisis:
```
MÃ©todo: ğŸ§  Experta
Max resultados: 50
Mostrar SPARQL: âœ“
Metadata completa: âœ“
Modo comparaciÃ³n: âœ—
```

---

## ğŸ“ˆ MÃ©tricas de Rendimiento

### âš¡ BÃºsqueda RÃ¡pida
```
Latencia promedio: 0.5ms - 2ms
PrecisiÃ³n: Media (70%)
Recall: Alto (85%)
Best for: Queries simples
```

### ğŸ¯ BÃºsqueda Inteligente
```
Latencia promedio:
  - Hybrid: 50ms - 200ms
  - LLM: 500ms - 2000ms
PrecisiÃ³n: Alta (85%)
Recall: Alto (82%)
Best for: Uso general
```

### ğŸ§  BÃºsqueda Experta
```
Latencia promedio: 2500ms - 6000ms
PrecisiÃ³n: Muy Alta (92%)
Recall: Medio (65%)
Best for: Queries complejas
```

---

## â“ FAQ - Preguntas Frecuentes

### P: Â¿QuÃ© mÃ©todo debo usar si no sÃ© quÃ© tan compleja es mi query?
**R**: Usa ğŸ¯ **Inteligente**. El router decidirÃ¡ automÃ¡ticamente.

### P: Â¿Por quÃ© un mÃ©todo dice "no aplica"?
**R**: Cada mÃ©todo tiene fortalezas diferentes. El error te sugerirÃ¡ quÃ© mÃ©todo usar.

### P: Â¿Puedo guardar mis bÃºsquedas favoritas?
**R**: El historial guarda las Ãºltimas 5 automÃ¡ticamente. Para persistencia, usa CSV/JSON.

### P: Â¿CÃ³mo sÃ© si mi query es de agregaciÃ³n?
**R**: Si usas palabras como "count", "average", "sum", "total", es agregaciÃ³n.

### P: Â¿El modo comparaciÃ³n es mÃ¡s lento?
**R**: SÃ­, ejecuta 3 mÃ©todos. Ãšsalo solo para aprender o comparar.

### P: Â¿Puedo usar espaÃ±ol?
**R**: SÃ­, pero el LLM funciona mejor en inglÃ©s. Para agregaciones en espaÃ±ol usa: "cuÃ¡ntos", "promedio", "suma".

---

## ğŸ“ Aprende MÃ¡s

### DocumentaciÃ³n TÃ©cnica:
- `docs/BUSQUEDA_MULTI_METODO.md` - DocumentaciÃ³n completa
- `experiments/benchmarks/evaluation_pipeline_v3.ipynb` - EvaluaciÃ³n de mÃ©todos

### Ejemplos en CÃ³digo:
- `app/pages/1_ğŸ”_BÃºsqueda.py` - ImplementaciÃ³n
- `experiments/benchmarks/keyword_bm25.py` - BM25 Baseline
- `experiments/benchmarks/hybrid_retrieval.py` - Hybrid Router
- `llm/text_to_sparql.py` - LLM + RAG

---

**Â¡Feliz BÃºsqueda! ğŸš€**
# ğŸ” BÃºsqueda Multi-MÃ©todo - DocumentaciÃ³n de Cambios

**Fecha**: 2026-02-16  
**Archivo modificado**: `app/pages/1_ğŸ”_BÃºsqueda.py`

---

## ğŸ“‹ Resumen de Cambios Implementados

Se ha rediseÃ±ado completamente la pÃ¡gina de bÃºsqueda para incluir **3 mÃ©todos diferentes**, **detecciÃ³n automÃ¡tica de tipo de query**, y **presentaciÃ³n diferenciada de resultados**.

---

## 1ï¸âƒ£ Tres MÃ©todos de BÃºsqueda con Nombres Intuitivos

### âš¡ **BÃºsqueda RÃ¡pida** (BM25 Baseline)
- **TecnologÃ­a**: BM25 con scoring de palabras clave
- **Latencia**: ~1ms
- **Mejor para**: Listados simples, bÃºsquedas directas por palabras
- **Ejemplo**: "PyTorch models", "computer vision models"
- **FunciÃ³n**: `execute_fast_search()`

### ğŸ¯ **BÃºsqueda Inteligente** (Router HÃ­brido)
- **TecnologÃ­a**: 
  - Hybrid (BM25 + Dense SBERT) para queries simples
  - LLM + RAG para queries complejas
- **Latencia**: ~100-1000ms
- **Mejor para**: Queries variadas con filtros
- **Ejemplo**: "top 10 PyTorch models", "high rated NLP models"
- **FunciÃ³n**: `execute_smart_search()`
- **LÃ³gica de routing**:
  ```python
  if is_complex_query(query):
      â†’ Use LLM + RAG
  else:
      â†’ Use Hybrid (BM25 + Dense)
  ```

### ğŸ§  **BÃºsqueda Experta** (LLM + RAG Completo)
- **TecnologÃ­a**: LLM (DeepSeek-R1:7b) + Ontology Dictionary + RAG
- **Latencia**: ~3-6s
- **Mejor para**: Agregaciones, queries complejas
- **Ejemplo**: "count models by framework", "average rating of CV models"
- **FunciÃ³n**: `execute_expert_search()`

---

## 2ï¸âƒ£ DetecciÃ³n AutomÃ¡tica del Tipo de Query

### FunciÃ³n: `detect_query_type(query, sparql)`

Detecta el tipo de consulta analizando:
1. **Patrones en SPARQL** (si estÃ¡ disponible):
   - `COUNT(`, `SUM(`, `AVG(`, `GROUP BY` â†’ AgregaciÃ³n
   - `ORDER BY` â†’ Ordenamiento
2. **Patrones en lenguaje natural**:
   - "count", "how many", "cuÃ¡ntos", "average" â†’ AgregaciÃ³n
   - "top", "best", "highest", "ordenar" â†’ Ordenamiento
   - Default â†’ Listado

### Tipos de Query:
- **`list`**: Consulta de listado simple
- **`aggregation`**: Consulta de agregaciÃ³n (COUNT, SUM, AVG, etc.)
- **`ordering`**: Consulta con ordenamiento (ORDER BY)
- **`complex`**: Consulta compleja (mÃºltiples condiciones)

---

## 3ï¸âƒ£ PresentaciÃ³n Diferenciada de Resultados

### Para Listados (tipo: `list`, `ordering`):
```
ğŸ“‹ Top N Modelos
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. bert-base-uncased           â”‚
â”‚ ğŸ“¦ Repositorio: HuggingFace    â”‚
â”‚ ğŸ¯ Tarea: NLP                  â”‚
â”‚ â­ Score: 0.95                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
- Tarjetas con diseÃ±o profesional
- Metadata expandible
- Descarga en JSON

### Para Agregaciones (tipo: `aggregation`):
```
ğŸ“Š Resultados de AgregaciÃ³n
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Framework  â”‚ Cantidad â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PyTorch    â”‚ 450      â”‚
â”‚ TensorFlow â”‚ 380      â”‚
â”‚ JAX        â”‚ 120      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
- Tabla interactiva con pandas
- Columnas con nombres legibles en espaÃ±ol
- Descarga en CSV

---

## 4ï¸âƒ£ Manejo de Errores Mejorado

### Antes:
```
âŒ Error ejecutando bÃºsqueda: ...
```

### Ahora:
```
âŒ Este mÃ©todo no puede procesar esta consulta

ğŸ’¡ Sugerencia: Este mÃ©todo es ideal para queries complejas:
   'count models by framework'
   'average rating of computer vision models'
   'models with more than 1000 downloads'
```

### Mensajes personalizados por mÃ©todo:
- **BÃºsqueda RÃ¡pida**: Sugiere queries simples por palabras clave
- **BÃºsqueda Inteligente**: Sugiere queries con filtrado o ranking
- **BÃºsqueda Experta**: Sugiere queries complejas y agregaciones

---

## 5ï¸âƒ£ Mejoras Adicionales Implementadas

### a) ğŸ”„ Modo ComparaciÃ³n
- **UbicaciÃ³n**: Checkbox en sidebar
- **FunciÃ³n**: Ejecuta los 3 mÃ©todos simultÃ¡neamente
- **Muestra**:
  - Resultados comparativos (tiempo, confianza, resultados)
  - Identifica el mejor mÃ©todo automÃ¡ticamente
  - Permite comparar fortalezas/debilidades

### b) ğŸ“œ Historial de BÃºsqueda
- **UbicaciÃ³n**: Sidebar (Ãºltimas 5 bÃºsquedas)
- **InformaciÃ³n guardada**:
  - Query original
  - MÃ©todo usado (con icono)
  - NÃºmero de resultados
  - Tiempo de ejecuciÃ³n
  - Timestamp

### c) ğŸ’¡ Ejemplos por CategorÃ­a
- **3 tabs organizados**:
  - ğŸ“‹ **Listados**: Queries simples
  - ğŸ“Š **Agregaciones**: COUNT, AVG, SUM
  - ğŸ” **Filtros Complejos**: TOP, ORDER BY, mÃºltiples condiciones
- **9 ejemplos ejecutables** con un clic

### d) ğŸ“¥ Exportar Resultados
- **Agregaciones**: CSV con columnas legibles
  - `count` â†’ `Cantidad`
  - `avg` â†’ `Promedio`
  - `task` â†’ `Tarea`
- **Listados**: JSON con metadata completa

### e) ğŸ¯ MÃ©tricas de Confianza
- **Niveles visuales**:
  - ğŸŸ¢ **High**: ConversiÃ³n exitosa con mÃºltiples resultados
  - ğŸŸ¡ **Medium**: ConversiÃ³n exitosa con pocos resultados
  - ğŸ”´ **Low**: Sin resultados o baja calidad
- **Basado en**:
  - ValidaciÃ³n del LLM
  - NÃºmero de resultados encontrados
  - Calidad del SPARQL generado

### f) ğŸ“Š InformaciÃ³n Detallada por MÃ©todo
- **Sidebar muestra para cada mÃ©todo**:
  - Icono descriptivo
  - DescripciÃ³n tÃ©cnica
  - Tiempo de ejecuciÃ³n aproximado
  - Mejor caso de uso

---

## ğŸ¨ Mejoras de UX Implementadas

1. **Radio buttons** para selecciÃ³n clara de mÃ©todo
2. **Tabs** para organizar ejemplos por tipo
3. **Expanders** para contenido secundario (SPARQL, metadata, historial)
4. **Progress spinners** con icono del mÃ©todo activo
5. **Color coding** para niveles de confianza
6. **Download buttons** para exportar datos
7. **Tooltips** con ayuda contextual

---

## ğŸ§ª CÃ³mo Probar el Sistema

### 1. Verificar Setup
```bash
cd /home/edmundo/ai-model-discovery

# Verificar que el grafo existe
ls -lh data/ai_models_multi_repo.ttl

# Verificar imports
python3 -c "import sys; sys.path.insert(0, 'experiments/benchmarks'); from keyword_bm25 import KeywordBM25Baseline; print('âœ… OK')"
```

### 2. Ejecutar Streamlit
```bash
cd /home/edmundo/ai-model-discovery
streamlit run app/main.py
```

### 3. Navegar a la PÃ¡gina
- Abrir navegador
- Ir a la pÃ¡gina **"1_ğŸ”_BÃºsqueda"**

### 4. Probar Cada MÃ©todo

#### Prueba 1: BÃºsqueda RÃ¡pida (âš¡)
- **Query**: "PyTorch models"
- **Esperado**: 
  - Listado de modelos PyTorch
  - Tiempo < 10ms
  - Confianza: Medium

#### Prueba 2: BÃºsqueda Inteligente (ğŸ¯)
- **Query Simple**: "PyTorch models for NLP"
- **Esperado**: 
  - Usa sub-mÃ©todo: `hybrid`
  - Listado con scores BM25+Dense
- **Query Compleja**: "count models by task"
- **Esperado**: 
  - Usa sub-mÃ©todo: `llm`
  - Tabla de agregaciÃ³n

#### Prueba 3: BÃºsqueda Experta (ğŸ§ )
- **Query**: "average rating of computer vision models"
- **Esperado**: 
  - Tabla de agregaciÃ³n
  - Muestra SPARQL generado
  - Ejemplos RAG usados

#### Prueba 4: Modo ComparaciÃ³n
- **Activar**: Checkbox "Modo comparaciÃ³n"
- **Query**: "top 10 PyTorch models"
- **Esperado**: 
  - Ejecuta 3 mÃ©todos
  - Muestra comparativa de tiempos
  - Identifica el mejor mÃ©todo

---

## ğŸ”§ Estructura del CÃ³digo

### Funciones Principales

```python
# ==================== SEARCH UTILITIES ====================
detect_query_type(query, sparql) â†’ (tipo, descripcion)
is_complex_query(query) â†’ bool
format_query_results_suggestion(query, method) â†’ str

# ==================== CACHE RESOURCES ====================
load_graph() â†’ (Graph, status_message)
load_bm25_engine() â†’ (engine, status_message)
load_hybrid_engine() â†’ (engine, status_message)
load_llm_engine() â†’ (engine, status_message)

# ==================== SEARCH METHODS ====================
execute_fast_search(query, top_k) â†’ Dict[str, Any]
execute_smart_search(query, top_k) â†’ Dict[str, Any]
execute_expert_search(query, top_k) â†’ Dict[str, Any]

# ==================== HELPER FUNCTIONS ====================
extract_model_metadata(graph, model_uri) â†’ Dict[str, Any]
format_sparql_results(graph, results, query, top_k) â†’ List[Dict]

# ==================== MAIN APP ====================
main() â†’ None
display_results(result, query, show_sparql, show_metadata) â†’ None
```

### Flujo de EjecuciÃ³n

```mermaid
User Input â†’ Select Method â†’ Execute Search
                â†“                    â†“
         [fast/smart/expert]   [BM25/Hybrid/LLM]
                                    â†“
                            Detect Query Type
                                    â†“
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â†“                       â†“
                   Listado                 AgregaciÃ³n
                        â†“                       â†“
                  Show Cards            Show Table (CSV)
                  Download JSON
```

---

## ğŸ“Š Comparativa de MÃ©todos

| CaracterÃ­stica | âš¡ RÃ¡pida | ğŸ¯ Inteligente | ğŸ§  Experta |
|---|---|---|---|
| **Latencia** | ~1ms | ~100-1000ms | ~3-6s |
| **TecnologÃ­a** | BM25 | Hybrid/LLM Router | LLM+RAG |
| **Listados** | âœ… Excelente | âœ… Excelente | âœ… Bueno |
| **Agregaciones** | âŒ No soporta | âœ… Bueno | âœ… Excelente |
| **Filtros Complejos** | âŒ Limitado | âœ… Bueno | âœ… Excelente |
| **ComprensiÃ³n SemÃ¡ntica** | âŒ No | âœ… Parcial | âœ… Completa |
| **Uso Recomendado** | ExploraciÃ³n rÃ¡pida | Uso general | AnÃ¡lisis profundo |

---

## ğŸš€ PrÃ³ximas Mejoras Sugeridas

### Corto Plazo (Sprint Actual)
1. **Cache de Embeddings**: Precalcular embeddings de queries comunes
2. **PaginaciÃ³n**: Para resultados > 50 items
3. **Filtros Post-Search**: Framework, task, source
4. **VisualizaciÃ³n de Stats**: GrÃ¡ficos de distribuciÃ³n

### Mediano Plazo
1. **Guardado de BÃºsquedas**: Persistir historial en DB
2. **ComparaciÃ³n Visual**: GrÃ¡ficos de performance por mÃ©todo
3. **Sugerencias Inteligentes**: Autocompletar basado en historial
4. **A/B Testing**: MÃ©tricas de uso por mÃ©todo

### Largo Plazo
1. **Fine-tuning del LLM**: Entrenar con queries especÃ­ficas del dominio
2. **Multi-idioma**: Soporte completo espaÃ±ol/inglÃ©s
3. **API REST**: Exponer mÃ©todos como endpoints
4. **Dashboard Analytics**: MÃ©tricas de uso y performance

---

## ğŸ› Errores Conocidos y Limitaciones

### Limitaciones Actuales
1. **BM25**: No soporta agregaciones ni queries complejas
2. **Hybrid**: Requiere CUDA para embeddings densos (fallback a CPU)
3. **LLM**: Dependiente de Ollama local (requiere ~8GB RAM)
4. **Cache**: Se limpia al reiniciar la app

### Soluciones Paliativas
1. BM25 muestra mensaje amigable al fallar
2. Hybrid usa CPU si no hay GPU
3. LLM muestra sugerencias si falla conversiÃ³n
4. Cache se recarga rÃ¡pidamente (<5s)

---

## ğŸ“š Referencias

- **MÃ³dulos de bÃºsqueda**: `experiments/benchmarks/`
  - `keyword_bm25.py`: BM25 Baseline
  - `hybrid_retrieval.py`: Hybrid (BM25 + Dense)
  - `ontology_enhanced_bm25.py`: BM25 con ontologÃ­a
  - `dense_retrieval.py`: SBERT embeddings

- **LLM**: `llm/text_to_sparql.py`
  - ConversiÃ³n de texto a SPARQL
  - RAG con ChromaDB
  - ValidaciÃ³n de queries

- **Notebook de evaluaciÃ³n**: `experiments/benchmarks/evaluation_pipeline_v3.ipynb`
  - MÃ©tricas de los 3 mÃ©todos
  - 90 queries de prueba
  - Resultados comparativos

---

## âœ… Checklist de ImplementaciÃ³n

- [x] Implementar 3 mÃ©todos de bÃºsqueda
- [x] Crear nombres cortos e intuitivos
- [x] Detectar tipo de query (listado vs agregaciÃ³n)
- [x] PresentaciÃ³n diferenciada de resultados
- [x] Manejo de errores amigable
- [x] Modo comparaciÃ³n de 3 mÃ©todos
- [x] Historial de bÃºsqueda (Ãºltimas 5)
- [x] Ejemplos organizados por categorÃ­a
- [x] Exportar resultados (CSV/JSON)
- [x] MÃ©tricas de confianza visual
- [x] DocumentaciÃ³n completa
- [x] Tests de importaciÃ³n exitosos
- [x] Backup del archivo original

---

## ğŸ‘¤ Autor

**Edmundo Mori**  
Fecha: 2026-02-16

---

## ğŸ“ Notas de VersiÃ³n

**VersiÃ³n 2.0** - Multi-MÃ©todo (2026-02-16)
- ImplementaciÃ³n completa de 3 mÃ©todos
- DetecciÃ³n automÃ¡tica de tipo de query
- PresentaciÃ³n diferenciada por tipo
- Modo comparaciÃ³n incluido
- 6 mejoras adicionales de UX

**VersiÃ³n 1.0** - Version Original
- Sistema Ãºnico con Phase 2/3/4
- Solo muestra mÃ©todo usado post-facto
- PresentaciÃ³n uniforme de resultados
# ğŸ“š Ejemplos RAG: MÃ©todos Inteligente y Experta

**Fecha**: 2026-02-16  
**Archivo fuente**: `llm/rag_sparql_examples.py`

---

## ğŸ“Š Resumen Ejecutivo

### Total de Ejemplos RAG Disponibles: **150**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NIVEL          â”‚  CANTIDAD              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Basic          â”‚  53 ejemplos (35.3%)   â”‚
â”‚  Intermediate   â”‚  40 ejemplos (26.7%)   â”‚
â”‚  Advanced       â”‚  57 ejemplos (38.0%)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TOTAL          â”‚  150 ejemplos          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Â¿QuÃ© MÃ©todos Usan RAG?

### âš¡ BÃºsqueda RÃ¡pida (BM25 Baseline)
- **Usa RAG**: âŒ No
- **Motivo**: BÃºsqueda por palabras clave puras, sin LLM

### ğŸ¯ BÃºsqueda Inteligente (Router)
- **Usa RAG**: âœ… SÃ­ (solo para queries complejas)
- **CuÃ¡ndo**: Si `is_complex_query(query) == True`
- **Sub-mÃ©todo**: Usa LLM+RAG (mismo que Experta)
- **Top-K ejemplos**: 3 ejemplos por defecto

### ğŸ§  BÃºsqueda Experta (LLM+RAG)
- **Usa RAG**: âœ… SÃ­ (siempre)
- **Motivo**: Todas las queries pasan por LLM
- **Top-K ejemplos**: 3 ejemplos por defecto

---

## ğŸ¯ Top 10 CategorÃ­as de Ejemplos

Las categorÃ­as mÃ¡s representadas en la base de conocimiento:

| # | CategorÃ­a | Ejemplos | DescripciÃ³n |
|---|-----------|----------|-------------|
| 1 | search_by_name | 5 | BÃºsqueda por nombre de modelo |
| 2 | filter_by_repository | 5 | Filtrar por repositorio |
| 3 | filter_by_task | 5 | Filtrar por tarea (NLP, CV, etc.) |
| 4 | filter_by_library | 5 | Filtrar por biblioteca (PyTorch, TF) |
| 5 | filter_by_metrics | 5 | Filtrar por mÃ©tricas (rating, downloads) |
| 6 | filter_by_domain | 5 | Filtrar por dominio |
| 7 | list_metadata | 5 | Listar metadata |
| 8 | filter_by_size | 5 | Filtrar por tamaÃ±o de modelo |
| 9 | filter_by_usecase | 5 | Filtrar por caso de uso |
| 10 | filter_by_architecture | 5 | Filtrar por arquitectura |

**Total de categorÃ­as Ãºnicas**: 106

---

## ğŸ” Proceso de RAG (Retrieval Augmented Generation)

### 1. **IndexaciÃ³n (Una vez al iniciar)**

```python
# En TextToSPARQLConverter.__init__()
1. Cargar 150 ejemplos desde rag_sparql_examples.py
2. Crear ChromaDB collection: "sparql_examples"
3. Para cada ejemplo:
   - Documento = natural_query + keywords
   - Metadata = id, complexity, category, explanation
4. Indexar con embeddings (DefaultEmbeddingFunction)
5. Guardar en: ~/.cache/ai_model_discovery/chroma/
```

### 2. **Retrieval (Por cada query)**

```python
# En TextToSPARQLConverter.convert(query)
1. Usuario ingresa: "PyTorch models for NLP"
2. ChromaDB busca los Top-3 ejemplos mÃ¡s similares
3. Calcula RAG score (similaridad promedio)
4. Retorna: [ejemplo1, ejemplo2, ejemplo3], score
```

### 3. **InyecciÃ³n Inteligente del Diccionario**

```python
# Estrategia basada en RAG score:
if rag_score > 0.8:
    # Ejemplos MUY similares â†’ Sin diccionario
    context = ""
    
elif rag_score >= 0.5:
    # Ejemplos MEDIANAMENTE similares â†’ Top 10 propiedades
    context = get_property_context_compact(top_10)
    
else:
    # Ejemplos POCO similares â†’ Diccionario completo
    context = get_property_context_detailed(all_properties)
```

### 4. **ConstrucciÃ³n del Prompt**

```python
# Prompt final enviado al LLM:
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

EJEMPLOS RELEVANTES:
{ejemplo1}
{ejemplo2}
{ejemplo3}

{diccionario de propiedades (si score < 0.8)}

USER QUERY: {query del usuario}

SPARQL:
```

---

## ğŸ’¡ Ejemplos RAG MÃ¡s Relevantes

### Ejemplo 1: "PyTorch models for NLP"

**ID**: `intermediate_001`

**Natural Query**: "PyTorch models for NLP"

**Keywords**: `pytorch`, `nlp`, `natural language`, `framework`, `library`, `text`

**SPARQL**:
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?model ?title ?source ?library ?task ?downloads
WHERE {
  ?model a daimo:Model ;
         dcterms:title ?title ;
         dcterms:source ?source ;
         daimo:library ?library .
  OPTIONAL { ?model daimo:task ?task }
  OPTIONAL { ?model daimo:downloads ?downloads }
  FILTER(
    CONTAINS(LCASE(?library), "pytorch") &&
    (!BOUND(?task) || CONTAINS(LCASE(?task), "nlp") || 
     CONTAINS(LCASE(?task), "language") || CONTAINS(LCASE(?task), "text"))
  )
}
ORDER BY DESC(?downloads)
LIMIT 15
```

**ExplicaciÃ³n**: PyTorch models con filtrado opcional de tarea NLP para evitar sobre-filtrado

---

### Ejemplo 2: "count models by task"

**ID**: `intermediate_003`

**Natural Query**: "count models for task"

**Keywords**: `count`, `group by`, `library`, `task`, `aggregate`

**SPARQL**:
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?library (COUNT(?model) as ?modelCount)
WHERE {
  ?model a daimo:Model ;
         daimo:library ?library .
}
GROUP BY ?library
ORDER BY DESC(?modelCount)
LIMIT 20
```

**ExplicaciÃ³n**: AgregaciÃ³n con COUNT y GROUP BY para contar modelos por biblioteca

---

### Ejemplo 3: "high rated computer vision models"

**ID**: `basic_002`

**Natural Query**: "high rated computer vision models"

**Keywords**: `high rated`, `likes`, `popular`, `computer vision`, `vision`, `image`, `cv`

**SPARQL**:
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?title ?likes ?downloads ?library
WHERE {
  ?model a daimo:Model ;
         dcterms:title ?title .
  OPTIONAL { ?model daimo:likes ?likes }
  OPTIONAL { ?model daimo:downloads ?downloads }
  OPTIONAL { ?model daimo:library ?library }
  FILTER(BOUND(?likes) && ?likes > 10)
}
ORDER BY DESC(?likes) DESC(?downloads)
LIMIT 15
```

**ExplicaciÃ³n**: Filtrado por likes (rating) con comparaciÃ³n numÃ©rica

---

## ğŸ§ª CÃ³mo Ver los Ejemplos RAG Usados

### En la Interfaz Web:

1. **Activar visualizaciÃ³n de SPARQL**:
   - Sidebar â†’ â˜‘ï¸ "Mostrar SPARQL generado"

2. **Ejecutar bÃºsqueda**:
   - Selecciona: ğŸ¯ Inteligente o ğŸ§  Experta
   - Query: "PyTorch models for NLP"
   - Clic: ğŸš€ Buscar

3. **Ver ejemplos usados**:
   - Expandir: "ğŸ“ SPARQL generado"
   - Al final verÃ¡s: "ğŸ“š Ejemplos RAG usados: intermediate_001, basic_003, basic_001"

---

## ğŸ“Š EstadÃ­sticas por Complejidad

### Basic (53 ejemplos)
- **Queries simples**: "list all models", "models from HuggingFace"
- **Filtros bÃ¡sicos**: Por source, library, task
- **Sin agregaciones**: Solo SELECT simple

### Intermediate (40 ejemplos)
- **Multi-criterio**: "PyTorch models for NLP"
- **Agregaciones simples**: COUNT, GROUP BY
- **Ordenamiento**: ORDER BY downloads, likes

### Advanced (57 ejemplos)
- **Agregaciones complejas**: AVG, SUM, MIN, MAX
- **MÃºltiples JOIN**: Relaciones entre entidades
- **Filtros avanzados**: HAVING, mÃºltiples OPTIONAL

---

## ğŸ”§ ConfiguraciÃ³n del Sistema RAG

### ParÃ¡metros por MÃ©todo:

#### ğŸ¯ BÃºsqueda Inteligente (sub-mÃ©todo LLM)
```python
TextToSPARQLConverter(
    model="deepseek-r1:7b",
    use_rag=True,              # âœ… RAG activado
    top_k_examples=3,          # Top-3 ejemplos
    temperature=0.0,           # DeterminÃ­stico
    llm_provider="ollama",     # Ollama local
    validation_graph=graph     # Grafo para validaciÃ³n
)
```

#### ğŸ§  BÃºsqueda Experta
```python
# Misma configuraciÃ³n que Inteligente (sub-mÃ©todo LLM)
TextToSPARQLConverter(
    model="deepseek-r1:7b",
    use_rag=True,              # âœ… RAG activado
    top_k_examples=3,          # Top-3 ejemplos
    temperature=0.0,           # DeterminÃ­stico
    llm_provider="ollama",
    validation_graph=graph
)
```

### Storage de ChromaDB:
```bash
~/.cache/ai_model_discovery/chroma/
â”œâ”€â”€ chroma.sqlite3           # Base de datos
â”œâ”€â”€ embeddings/              # Vectores de embeddings
â””â”€â”€ indices/                 # Ãndices de bÃºsqueda
```

---

## ğŸ“ Casos de Uso: QuÃ© Ejemplos se Usan

### Caso 1: Query Simple
**Input**: "PyTorch models"

**Ejemplos RAG Recuperados**:
1. `intermediate_001`: "PyTorch models for NLP"
2. `basic_003`: "models from HuggingFace" (menciona PyTorch)
3. `intermediate_002`: "most popular models by downloads"

**RAG Score**: 0.65 (medio)
**Diccionario**: Top 10 propiedades (compacto)

---

### Caso 2: Query Compleja de AgregaciÃ³n
**Input**: "count models by framework"

**Ejemplos RAG Recuperados**:
1. `intermediate_003`: "count models for task" (COUNT + GROUP BY)
2. `advanced_015`: "average rating by framework"
3. `advanced_022`: "sum downloads by library"

**RAG Score**: 0.85 (alto)
**Diccionario**: Sin diccionario (ejemplos suficientes)

---

### Caso 3: Query Muy EspecÃ­fica
**Input**: "models with more than 1000 downloads and rating > 4.5"

**Ejemplos RAG Recuperados**:
1. `intermediate_002`: "most popular models by downloads"
2. `basic_002`: "high rated computer vision models"
3. `advanced_008`: "models with multiple filters"

**RAG Score**: 0.45 (bajo)
**Diccionario**: Completo (~30 propiedades)

---

## ğŸ“ˆ MÃ©tricas de Efectividad del RAG

### SegÃºn Evaluation Pipeline v3:

| MÃ©todo | RAG Usado | Correctness | Completeness | Success Rate |
|--------|-----------|-------------|--------------|--------------|
| **ğŸ¯ Inteligente (LLM)** | âœ… SÃ­ | 18% | 50% | 97% |
| **ğŸ§  Experta** | âœ… SÃ­ | 15% | 39% | 94% |

**ObservaciÃ³n**: El RAG mejora significativamente la tasa de Ã©xito y completitud comparado con LLM sin RAG.

---

## ğŸ’¡ Tips para Mejorar el RAG

### 1. **Agregar mÃ¡s ejemplos**
Editar `llm/rag_sparql_examples.py` y agregar nuevos `SPARQLExample`:
```python
SPARQLExample(
    id="custom_001",
    natural_query="tu query",
    sparql_query="tu SPARQL",
    complexity="intermediate",
    category="custom_filter",
    keywords=["keyword1", "keyword2"],
    explanation="ExplicaciÃ³n"
)
```

### 2. **Limpiar cache de ChromaDB**
Si actualizas ejemplos, limpia la cache:
```bash
rm -rf ~/.cache/ai_model_discovery/chroma/
# Reiniciar app para reindexar
```

### 3. **Ajustar Top-K**
Para mÃ¡s contexto, aumentar `top_k_examples`:
```python
# En app/pages/1_ğŸ”_BÃºsqueda.py
llm_engine = TextToSPARQLConverter(
    ...
    top_k_examples=5,  # En vez de 3
    ...
)
```

### 4. **Mejorar Keywords**
AsegÃºrate que cada ejemplo tenga keywords relevantes y completas.

---

## ğŸ” CÃ³mo Verificar Ejemplos Manualmente

```python
# En Python:
from llm.rag_sparql_examples import get_all_examples

examples = get_all_examples()

# Ver un ejemplo especÃ­fico
pytorch_ex = [ex for ex in examples if ex.id == "intermediate_001"][0]
print(f"Query: {pytorch_ex.natural_query}")
print(f"Keywords: {pytorch_ex.keywords}")
print(f"SPARQL:\n{pytorch_ex.sparql_query}")

# Buscar por keyword
nlp_examples = [ex for ex in examples if "nlp" in ex.keywords]
print(f"Ejemplos con 'nlp': {len(nlp_examples)}")
```

---

## ğŸ“š Archivos Relacionados

- **Ejemplos RAG**: `llm/rag_sparql_examples.py` (3,245 lÃ­neas)
- **TextToSPARQL**: `llm/text_to_sparql.py` (825 lÃ­neas)
- **PÃ¡gina de bÃºsqueda**: `app/pages/1_ğŸ”_BÃºsqueda.py` (997 lÃ­neas)
- **Diccionario de ontologÃ­a**: `llm/ontology_dictionary.py`

---

## âœ… Resumen

- **150 ejemplos RAG** disponibles en 106 categorÃ­as
- **Top-3 ejemplos** recuperados por cada query
- **InyecciÃ³n inteligente** del diccionario segÃºn RAG score
- **ChromaDB persistente** en ~/.cache/
- **Usado por**: ğŸ¯ Inteligente (queries complejas) y ğŸ§  Experta (todas)

---

**Ãšltima actualizaciÃ³n**: 2026-02-16
# MÃ³dulo de BÃºsqueda

Este directorio contiene las implementaciones de los tres mÃ©todos de bÃºsqueda del proyecto.

## Estructura

- **`non_federated/`**: MÃ©todo 1 - BÃºsqueda semÃ¡ntica en un Ãºnico catÃ¡logo
- **`federated/`**: MÃ©todo 2 - BÃºsqueda federada SPARQL
- **`cross_repository/`**: MÃ©todo 3 - BÃºsqueda multi-fuente web-wide

## Estado Actual

| MÃ©todo | Estado | Fase |
|--------|--------|------|
| Non-federated | ğŸ“… Planificado | 2 (Semanas 3-4) |
| Federated | ğŸ“… Planificado | 3 (Semana 5) |
| Cross-repository | ğŸ“… Planificado | 4 (Semanas 6-7) |

## MÃ©todo 1: BÃºsqueda No Federada (PrÃ³ximamente)

Componentes a implementar:

1. `semantic_search.py`: Motor de bÃºsqueda principal
2. `query_interface.py`: CLI interactiva
3. `ranker.py`: Sistema de ranking de resultados

Pipeline:
```
Usuario â†’ Consulta NL â†’ LLM (text_to_sparql) â†’ SPARQL Query â†’ Grafo RDF â†’ Resultados â†’ Ranking
```

## MÃ©todo 2: BÃºsqueda Federada (Fase 3)

PermitirÃ¡ consultar mÃºltiples grafos RDF simultÃ¡neamente usando SPARQL federado.

## MÃ©todo 3: Cross-Repository (Fase 4)

IntegrarÃ¡ mÃºltiples fuentes:
- Hugging Face API
- Papers with Code
- OpenML
- Otros repositorios pÃºblicos

Ver [README.md](../README.md) principal para detalles del plan de implementaciÃ³n.
# Consultas SPARQL de Ejemplo

Este directorio contiene consultas SPARQL predefinidas para explorar el grafo de conocimiento de modelos de IA.

## Consultas BÃ¡sicas

### 1. Listar todos los modelos
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?model ?title ?created
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  OPTIONAL { ?model dcterms:created ?created }
}
ORDER BY DESC(?created)
LIMIT 10
```

### 2. Modelos por tarea
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?model ?title ?task
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model dcterms:subject ?task .
  FILTER(CONTAINS(?task, "classification"))
}
LIMIT 20
```

### 3. Modelos con licencia especÃ­fica
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>
PREFIX odrl: <http://www.w3.org/ns/odrl/2/>

SELECT ?model ?title ?license
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model odrl:hasPolicy ?licenseObj .
  ?licenseObj dcterms:identifier ?license .
  FILTER(CONTAINS(?license, "mit"))
}
```

### 4. Modelos mÃ¡s populares
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?model ?title ?downloads ?likes
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  OPTIONAL { ?model daimo:downloads ?downloads }
  OPTIONAL { ?model daimo:likes ?likes }
}
ORDER BY DESC(?downloads)
LIMIT 10
```

### 5. Modelos por autor
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>
PREFIX foaf: <http://xmlns.com/foaf/0.1/>

SELECT ?model ?title ?author
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model dcterms:creator ?authorObj .
  ?authorObj foaf:name ?author .
}
```

### 6. Modelos entrenados con dataset especÃ­fico
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>
PREFIX prov: <http://www.w3.org/ns/prov#>
PREFIX dcat: <http://www.w3.org/ns/dcat#>

SELECT ?model ?title ?dataset
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model prov:wasDerivedFrom ?datasetObj .
  ?datasetObj dcterms:identifier ?dataset .
}
```

### 7. Modelos por librerÃ­a/framework
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?model ?title ?library
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model daimo:library ?library .
  FILTER(?library = "transformers")
}
```

### 8. EstadÃ­sticas por tarea
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?task (COUNT(?model) as ?count)
WHERE {
  ?model a daimo:Model .
  ?model dcterms:subject ?task .
}
GROUP BY ?task
ORDER BY DESC(?count)
```

## Consultas Avanzadas

### 9. Modelos multilingÃ¼es
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?model ?title (COUNT(?lang) as ?numLanguages)
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model dcterms:language ?lang .
}
GROUP BY ?model ?title
HAVING (COUNT(?lang) > 1)
ORDER BY DESC(?numLanguages)
```

### 10. Modelos con mÃºltiples tags
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>
PREFIX dcat: <http://www.w3.org/ns/dcat#>

SELECT ?model ?title (GROUP_CONCAT(?keyword; separator=", ") as ?tags)
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model dcat:keyword ?keyword .
}
GROUP BY ?model ?title
LIMIT 10
```

## Uso

Las consultas se pueden ejecutar usando:

1. **Python con RDFLib**:
```python
from knowledge_graph import DAIMOGraphBuilder

builder = DAIMOGraphBuilder()
builder.build_from_json("data/raw/hf_models.json")

query = """
PREFIX daimo: <http://purl.org/pionera/daimo#>
SELECT ?model WHERE { ?model a daimo:Model }
"""

results = builder.query(query)
for row in results:
    print(row)
```

2. **Desde el notebook de validaciÃ³n** (notebooks/01_validation.ipynb)

3. **Herramientas externas**:
   - Apache Jena Fuseki
   - GraphDB
   - ProtÃ©gÃ©
# Consultas SPARQL de Ejemplo

Este directorio contiene consultas SPARQL predefinidas para explorar el grafo de conocimiento de modelos de IA.

## Consultas BÃ¡sicas

### 1. Listar todos los modelos
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?model ?title ?created
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  OPTIONAL { ?model dcterms:created ?created }
}
ORDER BY DESC(?created)
LIMIT 10
```

### 2. Modelos por tarea
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?model ?title ?task
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model dcterms:subject ?task .
  FILTER(CONTAINS(?task, "classification"))
}
LIMIT 20
```

### 3. Modelos con licencia especÃ­fica
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>
PREFIX odrl: <http://www.w3.org/ns/odrl/2/>

SELECT ?model ?title ?license
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model odrl:hasPolicy ?licenseObj .
  ?licenseObj dcterms:identifier ?license .
  FILTER(CONTAINS(?license, "mit"))
}
```

### 4. Modelos mÃ¡s populares
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?model ?title ?downloads ?likes
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  OPTIONAL { ?model daimo:downloads ?downloads }
  OPTIONAL { ?model daimo:likes ?likes }
}
ORDER BY DESC(?downloads)
LIMIT 10
```

### 5. Modelos por autor
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>
PREFIX foaf: <http://xmlns.com/foaf/0.1/>

SELECT ?model ?title ?author
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model dcterms:creator ?authorObj .
  ?authorObj foaf:name ?author .
}
```

### 6. Modelos entrenados con dataset especÃ­fico
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>
PREFIX prov: <http://www.w3.org/ns/prov#>
PREFIX dcat: <http://www.w3.org/ns/dcat#>

SELECT ?model ?title ?dataset
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model prov:wasDerivedFrom ?datasetObj .
  ?datasetObj dcterms:identifier ?dataset .
}
```

### 7. Modelos por librerÃ­a/framework
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?model ?title ?library
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model daimo:library ?library .
  FILTER(?library = "transformers")
}
```

### 8. EstadÃ­sticas por tarea
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?task (COUNT(?model) as ?count)
WHERE {
  ?model a daimo:Model .
  ?model dcterms:subject ?task .
}
GROUP BY ?task
ORDER BY DESC(?count)
```

## Consultas Avanzadas

### 9. Modelos multilingÃ¼es
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?model ?title (COUNT(?lang) as ?numLanguages)
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model dcterms:language ?lang .
}
GROUP BY ?model ?title
HAVING (COUNT(?lang) > 1)
ORDER BY DESC(?numLanguages)
```

### 10. Modelos con mÃºltiples tags
```sparql
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>
PREFIX dcat: <http://www.w3.org/ns/dcat#>

SELECT ?model ?title (GROUP_CONCAT(?keyword; separator=", ") as ?tags)
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model dcat:keyword ?keyword .
}
GROUP BY ?model ?title
LIMIT 10
```

## Uso

Las consultas se pueden ejecutar usando:

1. **Python con RDFLib**:
```python
from knowledge_graph import DAIMOGraphBuilder

builder = DAIMOGraphBuilder()
builder.build_from_json("data/raw/hf_models.json")

query = """
PREFIX daimo: <http://purl.org/pionera/daimo#>
SELECT ?model WHERE { ?model a daimo:Model }
"""

results = builder.query(query)
for row in results:
    print(row)
```

2. **Desde el notebook de validaciÃ³n** (notebooks/01_validation.ipynb)

3. **Herramientas externas**:
   - Apache Jena Fuseki
   - GraphDB
   - ProtÃ©gÃ©

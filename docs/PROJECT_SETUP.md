# Gu√≠a de Inicio R√°pido

## Instalaci√≥n y Configuraci√≥n

### 1. Instalar Poetry (si no est√° instalado)

```bash
curl -sSL https://install.python-poetry.org | python3 -
```

### 2. Instalar dependencias del proyecto

```bash
cd /home/edmundo/ai-model-discovery
poetry install
```

Esto instalar√° todas las dependencias definidas en `pyproject.toml`.

### 3. Activar el entorno virtual

```bash
poetry shell
```

### 4. Configurar variables de entorno

```bash
cp .env.example .env
nano .env  # Editar con tus API keys
```

Necesitar√°s al menos una API key de:
- **OpenAI**: https://platform.openai.com/api-keys
- **Anthropic**: https://console.anthropic.com/

## Uso B√°sico

### Paso 1: Recolectar modelos de Hugging Face

```bash
# Recolectar 50 modelos (muestra peque√±a)
poetry run python -m utils.collect_hf_models --limit 50 --output hf_models_sample.json

# Recolectar 100 modelos ordenados por descargas
poetry run python -m utils.collect_hf_models --limit 100 --sort downloads

# Filtrar por tarea espec√≠fica
poetry run python -m utils.collect_hf_models --limit 50 --task text-classification
```

Los metadatos se guardan en `data/raw/`.

### Paso 2: Construir el grafo RDF

```bash
# Usando los datos recolectados
poetry run python knowledge_graph/build_graph.py \
  --input data/raw/hf_models_sample.json \
  --output data/processed/knowledge_graph.ttl \
  --format turtle
```

### Paso 3: Explorar con el notebook

```bash
# Iniciar Jupyter
poetry run jupyter notebook

# Abrir: notebooks/01_validation.ipynb
```

## Estructura del Workflow

```
1. Recolecci√≥n      2. Transformaci√≥n    3. Consulta
   (HF API)    ‚Üí    (RDF Graph)      ‚Üí    (SPARQL)
     ‚îÇ                   ‚îÇ                    ‚îÇ
     ‚îú‚îÄ JSON            ‚îú‚îÄ Turtle            ‚îú‚îÄ Manual
     ‚îî‚îÄ Metadatos       ‚îî‚îÄ DAIMO             ‚îî‚îÄ LLM (Fase 2)
```

## Ejemplos R√°pidos

### Consulta SPARQL desde Python

```python
from knowledge_graph import DAIMOGraphBuilder

# Cargar grafo
builder = DAIMOGraphBuilder()
builder.build_from_json("data/raw/hf_models_sample.json")

# Consultar
query = """
PREFIX daimo: <http://purl.org/pionera/daimo#>
PREFIX dcterms: <http://purl.org/dc/terms/>

SELECT ?title ?task
WHERE {
  ?model a daimo:Model .
  ?model dcterms:title ?title .
  ?model dcterms:subject ?task .
}
LIMIT 5
"""

results = builder.query(query)
for row in results:
    print(f"{row.title} - {row.task}")
```

## Soluci√≥n de Problemas

### Error: "ModuleNotFoundError"
```bash
# Aseg√∫rate de estar en el entorno de Poetry
poetry shell
```

### Error: API keys no configuradas
```bash
# Verificar que .env existe y tiene las keys
cat .env
```

### Error: Memoria insuficiente
```bash
# Reducir el l√≠mite de modelos
poetry run python -m utils.collect_hf_models --limit 20
```

## Pr√≥ximos Pasos

Una vez validada la Fase 1, continuar con:

1. **Fase 2**: Implementar Text-to-SPARQL con LLM
2. **Fase 3**: B√∫squeda federada
3. **Fase 4**: Cross-repository search

Ver [README.md](README.md) para el plan completo.
# Gu√≠a de Configuraci√≥n de APIs

Esta gu√≠a te ayudar√° a configurar las APIs de cada repositorio para obtener datos reales.

## üìã Resumen

| Repositorio | API P√∫blica | Requiere Auth | Dificultad | Estado |
|-------------|-------------|---------------|------------|--------|
| **HuggingFace** | ‚úÖ S√≠ | ‚ö†Ô∏è Opcional | üü¢ F√°cil | ‚úÖ Implementado |
| **Civitai** | ‚úÖ S√≠ | ‚ùå No | üü¢ F√°cil | ‚úÖ Implementado |
| **Papers With Code** | ‚úÖ S√≠ | ‚ùå No | üü¢ F√°cil | ‚úÖ Implementado |
| **Kaggle** | ‚úÖ S√≠ | ‚úÖ S√≠ | üü° Media | ‚úÖ Implementado |
| **Replicate** | ‚úÖ S√≠ | ‚úÖ S√≠ | üü° Media | üîÑ En implementaci√≥n |
| **Azure AI** | ‚úÖ S√≠ | ‚úÖ S√≠ | üî¥ Dif√≠cil | ‚ö†Ô∏è Pendiente |

---

## 1. HuggingFace Hub ü§ó

### Estado
‚úÖ **Completamente funcional** - API implementada y probada

### Configuraci√≥n (Opcional pero Recomendado)

Sin token puedes hacer ~50 consultas/hora. Con token: ilimitado.

```bash
# Obtener token de: https://huggingface.co/settings/tokens

# Opci√≥n 1: Variable de entorno
export HF_TOKEN="hf_xxxxxxxxxxxxxxxxxxxxx"

# Opci√≥n 2: Usar huggingface-cli
huggingface-cli login
```

### Uso en el c√≥digo

```python
from utils.huggingface_repository import HuggingFaceRepository

# Autom√°ticamente usa el token si est√° configurado
hf_repo = HuggingFaceRepository()
models = hf_repo.fetch_models(limit=50)
```

---

## 2. Civitai üé®

### Estado
‚úÖ **API real implementada** - Sin autenticaci√≥n requerida

### Configuraci√≥n

**No requiere configuraci√≥n** - API completamente p√∫blica

- Rate limit: ~60 req/minuto
- Documentaci√≥n: https://github.com/civitai/civitai/wiki/REST-API-Reference

### Uso en el c√≥digo

```python
from utils.civitai_repository import CivitaiRepository

# Sin configuraci√≥n necesaria
civitai_repo = CivitaiRepository()
models = civitai_repo.fetch_models(limit=50)
```

### Nota sobre contenido NSFW

Civitai incluye modelos NSFW. El c√≥digo mapea autom√°ticamente:
- `nsfw: true` ‚Üí `daimo:requiresApproval = true`
- `nsfwLevel` ‚Üí metadata para filtrado

---

## 3. Papers With Code üìÑ

### Estado
‚úÖ **API real implementada** - Sin autenticaci√≥n requerida

### Configuraci√≥n

**No requiere configuraci√≥n** - API completamente p√∫blica

- Rate limit: ~100 req/minuto
- Documentaci√≥n: https://paperswithcode.com/api/v1/docs/

### Uso en el c√≥digo

```python
from utils.pwc_repository import PWCRepository

# Sin configuraci√≥n necesaria
pwc_repo = PWCRepository()
models = pwc_repo.fetch_models(limit=50)
```

### C√≥mo funciona

1. Consulta papers recientes con implementaciones
2. Por cada paper, obtiene sus repositorios de c√≥digo
3. Selecciona el repo m√°s popular (m√°s estrellas)
4. Mapea paper ‚Üí Algorithm y repo ‚Üí Model

---

## 4. Kaggle üèÖ

### Estado
‚úÖ **API real implementada** - Requiere autenticaci√≥n

### Configuraci√≥n

#### Paso 1: Obtener credenciales

1. Ir a https://www.kaggle.com/settings/account
2. Scroll down a "API" section
3. Click "Create New API Token"
4. Descargar `kaggle.json`

#### Paso 2: Configurar credenciales

**Opci√≥n A: Archivo de configuraci√≥n (Recomendado)**

```bash
mkdir -p ~/.kaggle
mv ~/Downloads/kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json
```

**Opci√≥n B: Variables de entorno**

```bash
export KAGGLE_USERNAME="your_username"
export KAGGLE_KEY="your_api_key"
```

#### Paso 3: Instalar SDK

```bash
pip install kaggle
```

### Uso en el c√≥digo

```python
from utils.kaggle_repository import KaggleRepository

# Autom√°ticamente usa credenciales de ~/.kaggle/kaggle.json o env vars
kaggle_repo = KaggleRepository()
models = kaggle_repo.fetch_models(limit=50)
```

### Fallback autom√°tico

Si las credenciales no est√°n configuradas, el c√≥digo usa datos de ejemplo autom√°ticamente.

---

## 5. Replicate üîÅ

### Estado
üîÑ **En implementaci√≥n** - Requiere autenticaci√≥n obligatoria

### Configuraci√≥n

#### Paso 1: Obtener API Token

1. Crear cuenta en https://replicate.com
2. Ir a https://replicate.com/account/api-tokens
3. Click en "Create token"
4. Copiar el token (comienza con `r8_...`)

#### Paso 2: Configurar token

**Opci√≥n A: Variable de entorno (Recomendado)**

```bash
# En ~/.bashrc o ~/.zshrc
export REPLICATE_API_TOKEN="r8_xxxxxxxxxxxxxxxxxxxxx"

# O solo para la sesi√≥n actual
export REPLICATE_API_TOKEN="r8_xxxxxxxxxxxxxxxxxxxxx"
```

**Opci√≥n B: Archivo .env**

```bash
# En el directorio del proyecto
echo 'REPLICATE_API_TOKEN=r8_xxxxxxxxxxxxxxxxxxxxx' >> .env
```

#### Paso 3: Instalar SDK

```bash
pip install replicate
```

### Uso en el c√≥digo

```python
from utils.replicate_repository import ReplicateRepository

# Autom√°ticamente usa REPLICATE_API_TOKEN del entorno
replicate_repo = ReplicateRepository()
models = replicate_repo.fetch_models(limit=50)
```

### Verificar configuraci√≥n

```python
import os

token = os.getenv('REPLICATE_API_TOKEN')
if token:
    print(f"‚úÖ Token configurado: {token[:10]}...")
else:
    print("‚ùå Token no encontrado")
```

### Rate Limits

- **Crear predicci√≥n**: 600 requests/minuto
- **Otros endpoints**: 3000 requests/minuto

---

## 6. Azure AI ‚òÅÔ∏è

### Estado
‚ö†Ô∏è **Pendiente de implementaci√≥n completa** - Requiere cuenta de Azure

### Configuraci√≥n (Para implementaci√≥n futura)

#### Requisitos

- Cuenta de Azure activa
- Suscripci√≥n con Azure Machine Learning habilitado
- Service Principal o credenciales de usuario

#### Opci√≥n 1: Azure CLI (M√°s f√°cil)

```bash
# Instalar Azure CLI
curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

# Login
az login

# Verificar suscripci√≥n
az account show
```

#### Opci√≥n 2: Service Principal

```bash
# Crear service principal
az ad sp create-for-rbac --name "ai-model-discovery" --role contributor

# Configurar variables de entorno
export AZURE_SUBSCRIPTION_ID="your-subscription-id"
export AZURE_TENANT_ID="your-tenant-id"
export AZURE_CLIENT_ID="your-client-id"
export AZURE_CLIENT_SECRET="your-client-secret"
```

#### Paso 3: Instalar SDK

```bash
pip install azure-ai-ml azure-identity
```

### Uso en el c√≥digo (cuando se implemente)

```python
from utils.azure_repository import AzureRepository

# Usar√° credenciales de Azure CLI o variables de entorno
azure_repo = AzureRepository()
models = azure_repo.fetch_models(limit=50)
```

### Por qu√© es m√°s complejo

- Requiere cuenta de pago (no hay tier gratuito completo)
- Autenticaci√≥n m√°s compleja (AAD)
- API m√°s enfocada en deployment que en discovery
- Modelos suelen ser privados por workspace

---

## üöÄ Uso R√°pido - Solo APIs P√∫blicas

Si quieres empezar **sin configurar nada**:

```python
from utils.huggingface_repository import HuggingFaceRepository
from utils.civitai_repository import CivitaiRepository
from utils.pwc_repository import PWCRepository
from knowledge_graph.multi_repository_builder import MultiRepositoryGraphBuilder

# Estos 3 NO requieren autenticaci√≥n
repositories = [
    HuggingFaceRepository(),  # Mejor con token pero funciona sin √©l
    CivitaiRepository(),       # Completamente p√∫blico
    PWCRepository()            # Completamente p√∫blico
]

builder = MultiRepositoryGraphBuilder()
models_added = builder.build_from_repositories(repositories, limit_per_repo=10)
builder.save("data/processed/kg_public_apis.ttl")

print(f"‚úÖ {models_added} modelos recolectados sin configuraci√≥n!")
```

---

## üìä Comparaci√≥n de APIs

### Facilidad de Uso

1. **Civitai** üü¢ - M√°s f√°cil (sin auth, bien documentado)
2. **Papers With Code** üü¢ - F√°cil (sin auth)
3. **HuggingFace** üü° - F√°cil con token
4. **Kaggle** üü° - Media (requiere cuenta + API key)
5. **Replicate** üü° - Media (requiere cuenta + API token)
6. **Azure** üî¥ - Dif√≠cil (requiere suscripci√≥n de pago)

### Calidad de Datos

1. **HuggingFace** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê - Metadatos m√°s completos
2. **Papers With Code** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê - Papers acad√©micos + c√≥digo
3. **Replicate** ‚≠ê‚≠ê‚≠ê‚≠ê - Inference endpoints + run counts
4. **Civitai** ‚≠ê‚≠ê‚≠ê‚≠ê - Modelos de difusi√≥n bien documentados
4. **Kaggle** ‚≠ê‚≠ê‚≠ê - Buena comunidad pero menos modelos
5. **Azure** ‚≠ê‚≠ê‚≠ê - Modelos empresariales pero privados

### Rate Limits

| API | L√≠mite sin Auth | L√≠mite con Auth |
|-----|-----------------|-----------------|
| HuggingFace | ~50/hora | Ilimitado |
| Civitai | ~60/min | ~120/min (con key) |
| Papers With Code | ~100/min | N/A |
| Kaggle | N/A | ~100/hora |
| Azure | N/A | Depende del tier |

---

## üîß Troubleshooting

### Error: "Kaggle credentials not found"

```bash
# Verificar ubicaci√≥n del archivo
ls -la ~/.kaggle/kaggle.json

# Verificar permisos
chmod 600 ~/.kaggle/kaggle.json

# O usar variables de entorno
export KAGGLE_USERNAME="your_username"
export KAGGLE_KEY="your_api_key"
```

### Error: "Rate limit exceeded" (Civitai/PWC)

- Reducir `limit_per_repo`
- A√±adir delay entre requests
- Para Civitai: considerar obtener API key

### Error: "Azure authentication failed"

```bash
# Re-login con Azure CLI
az logout
az login

# Verificar suscripci√≥n activa
az account list
```

---

## üìù Notas Importantes

1. **Fallback autom√°tico**: Si una API falla, el sistema usa datos de ejemplo y contin√∫a
2. **Privacidad**: Nunca commitear `.env` o `kaggle.json` al repositorio
3. **Testing**: Siempre probar con `limit=5` primero para verificar autenticaci√≥n
4. **Costos**: Solo Azure tiene costos asociados (suscripci√≥n)

---

## üéØ Pr√≥ximos Pasos

1. ‚úÖ Configurar Civitai (no requiere nada)
2. ‚úÖ Configurar Papers With Code (no requiere nada)
3. üü° Configurar HuggingFace (recomendado: obtener token)
4. üü° Configurar Kaggle (requiere: crear cuenta + API key)
5. üî¥ Configurar Azure (requiere: suscripci√≥n de pago)

**Recomendaci√≥n**: Empieza con Civitai y PWC (sin configuraci√≥n), a√±ade HuggingFace con token, y opcionalmente Kaggle si tienes cuenta.
# üöÄ Plan de Implementaci√≥n - Extensi√≥n de Metadatos

**Proyecto**: AI Model Discovery System  
**Fase**: Pre-Fase 2 (Enriquecimiento de Ontolog√≠a)  
**Estado**: Planificaci√≥n

---

## üìã Checklist de Implementaci√≥n

### ‚úÖ Sprint 1: Metadatos Cr√≠ticos (1-2 d√≠as)

- [ ] **1.1. Extender ontolog√≠a DAIMO**
  - [ ] A√±adir clase `daimo:ModelArchitecture`
  - [ ] A√±adir clase `daimo:AccessPolicy`
  - [ ] A√±adir propiedades: `daimo:hasArchitecture`, `daimo:accessControl`, `daimo:requiresApproval`
  - [ ] Validar sintaxis con `rapper` o Prot√©g√©

- [ ] **1.2. Actualizar colector HuggingFace**
  - [ ] Extraer `model_type` y `architectures` del `config`
  - [ ] Extraer `gated` y tipo de gatekeeping
  - [ ] Extraer `safetensors.parameters` para conteo
  - [ ] A√±adir manejo de errores robusto
  
- [ ] **1.3. Actualizar graph builder**
  - [ ] Mapear `architectures` ‚Üí `daimo:hasArchitecture`
  - [ ] Mapear `gated` ‚Üí `daimo:AccessPolicy`
  - [ ] A√±adir `daimo:parameterCount`
  
- [ ] **1.4. Validaci√≥n**
  - [ ] Regenerar grafo con 50 modelos
  - [ ] Consultas SPARQL de validaci√≥n
  - [ ] Verificar nuevos triples

---

### üî∏ Sprint 2: Evaluaci√≥n y Performance (2-3 d√≠as)

- [ ] **2.1. Extender ontolog√≠a**
  - [ ] Integrar `mls:ModelEvaluation` de ML-Schema
  - [ ] A√±adir `daimo:fineTunedFrom`
  - [ ] A√±adir `daimo:parameterCount` (si no se hizo en Sprint 1)

- [ ] **2.2. Actualizar colector**
  - [ ] Extraer `metrics` del card_data
  - [ ] Extraer `model-index` (eval_results)
  - [ ] Extraer `base_model`
  - [ ] Parsear resultados de benchmarks

- [ ] **2.3. Actualizar graph builder**
  - [ ] Crear nodos `mls:ModelEvaluation` por cada m√©trica
  - [ ] Mapear `base_model` ‚Üí `daimo:fineTunedFrom`
  - [ ] A√±adir valores de evaluaci√≥n

- [ ] **2.4. Validaci√≥n**
  - [ ] Consultas SPARQL avanzadas (filtrar por accuracy, etc.)
  - [ ] Verificar proveniencia de fine-tuning

---

### üîπ Sprint 3: Contexto T√©cnico (1-2 d√≠as)

- [ ] **3.1. Extender ontolog√≠a**
  - [ ] A√±adir `daimo:HyperparameterConfiguration`
  - [ ] A√±adir `daimo:hasConfiguration`
  - [ ] A√±adir `daimo:usedByApplication`

- [ ] **3.2. Actualizar colector**
  - [ ] Extraer `config` completo (como JSON string o dict)
  - [ ] Extraer lista de `spaces`
  - [ ] Extraer `tokenizer_config` (opcional)

- [ ] **3.3. Actualizar graph builder**
  - [ ] Serializar `config` como JSON-LD o string
  - [ ] Mapear `spaces` ‚Üí `foaf:Project` + `daimo:usedByApplication`

---

### üîπ Sprint 4: Opcionales (1 d√≠a)

- [ ] **4.1. Sostenibilidad**
  - [ ] `daimo:carbonFootprint` ‚Üí `co2_eq_emissions`
  
- [ ] **4.2. Inferencia**
  - [ ] `daimo:inferenceEndpoint` ‚Üí `inference`

---

## üß™ Tests y Validaci√≥n

### Consultas SPARQL de Validaci√≥n

```sparql
# Test 1: Modelos por arquitectura
PREFIX daimo: <http://purl.org/pionera/daimo#>
SELECT ?model ?arch WHERE {
  ?model daimo:hasArchitecture ?archNode .
  ?archNode rdfs:label ?arch .
}

# Test 2: Modelos gated
PREFIX daimo: <http://purl.org/pionera/daimo#>
SELECT ?model ?gated WHERE {
  ?model daimo:requiresApproval ?gated .
  FILTER(?gated = true)
}

# Test 3: Modelos por n√∫mero de par√°metros
PREFIX daimo: <http://purl.org/pionera/daimo#>
SELECT ?model ?params WHERE {
  ?model daimo:parameterCount ?params .
  FILTER(?params > 1000000000)  # > 1B par√°metros
}
ORDER BY DESC(?params)

# Test 4: Modelos fine-tuneados
PREFIX daimo: <http://purl.org/pionera/daimo#>
SELECT ?model ?base WHERE {
  ?model daimo:fineTunedFrom ?base .
}

# Test 5: Modelos con evaluaci√≥n > 0.9
PREFIX mls: <http://www.w3.org/ns/mls#>
SELECT ?model ?metric ?value WHERE {
  ?model mls:hasEvaluation ?eval .
  ?eval mls:specifiedBy ?metric .
  ?eval mls:hasValue ?value .
  FILTER(?value > 0.9)
}
```

---

## üìä M√©tricas de √âxito

| M√©trica | Baseline Actual | Objetivo Post-Extensi√≥n |
|---------|----------------|------------------------|
| Campos capturados por modelo | ~12 | ~25 |
| Triples por modelo | ~40 | ~80-100 |
| Clases DAIMO | 2-3 | 6-8 |
| Propiedades DAIMO | ~10 | ~20 |
| Cobertura de metadatos cr√≠ticos | 60% | 95% |

---

## üö¶ Criterios de Aceptaci√≥n

### Para proceder a Fase 2, debe cumplirse:

1. ‚úÖ **Ontolog√≠a DAIMO extendida** con al menos las clases/propiedades del Sprint 1 + 2
2. ‚úÖ **Colector HuggingFace** captura todos los campos de Nivel 1 + 2 (25 campos)
3. ‚úÖ **Graph builder** mapea correctamente los nuevos campos
4. ‚úÖ **Validaci√≥n exitosa** de las 5 consultas SPARQL de test
5. ‚úÖ **Documentaci√≥n actualizada** del mapeo ontol√≥gico
6. ‚úÖ **Grafo de prueba** con 100+ modelos enriquecidos

---

## üîÑ Flujo de Trabajo

```mermaid
graph TD
    A[Extender daimo.ttl] --> B[Actualizar collect_hf_models.py]
    B --> C[Actualizar build_graph.py]
    C --> D[Regenerar grafo de validaci√≥n]
    D --> E[Tests SPARQL]
    E --> F{¬øTests OK?}
    F -->|No| B
    F -->|S√≠| G[Recolecci√≥n masiva 1000+ modelos]
    G --> H[Fase 2: Text-to-SPARQL]
```

---

## üìù Notas de Implementaci√≥n

### Consideraciones T√©cnicas

1. **Manejo de None/null**: Muchos campos opcionales pueden estar ausentes
2. **Parseo de config**: `config` puede ser muy grande; considerar almacenar solo keys relevantes
3. **Evaluaciones m√∫ltiples**: Un modelo puede tener m√∫ltiples evaluaciones en diferentes datasets
4. **Versiones de modelo**: Hugging Face permite m√∫ltiples versiones (commits); por ahora capturamos solo la √∫ltima

### Optimizaciones

- **Batch processing**: Procesar modelos en lotes para evitar timeouts
- **Cach√©**: Guardar respuestas de API para evitar re-consultas
- **Rate limiting**: Respetar l√≠mites de Hugging Face API

---

## üéØ Entrega Final

**Artefactos esperados**:
1. `ontologies/daimo.ttl` (extendido)
2. `utils/collect_hf_models.py` (v2 con 25 campos)
3. `knowledge_graph/build_graph.py` (v2 con nuevo mapeo)
4. `data/processed/kg_enriched.ttl` (grafo enriquecido)
5. `docs/ONTOLOGY_MAPPING.md` (tabla completa de mapeo)
6. `tests/test_enriched_queries.py` (tests automatizados)

**Timeline estimado**: 5-7 d√≠as de trabajo

**Siguiente milestone**: Iniciar Fase 2 con ontolog√≠a robusta y metadatos completos
